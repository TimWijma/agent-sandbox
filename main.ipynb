{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c5df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asteval import Interpreter\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "import re\n",
    "import math\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b599c134",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e0efd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "aeval = Interpreter()\n",
    "aeval.symtable['math'] = math\n",
    "\n",
    "gemini_client = genai.Client(api_key=GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84294934",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_message(user_input: str) -> str:\n",
    "    system_message = \"\"\"\n",
    "    You are a versatile AI assistant.\n",
    "    For each user query:\n",
    "    - Math queries: Respond ONLY with: USE_CALCULATOR: <valid Python expression>\n",
    "        Do NOT solve or simplify expressions yourself.\n",
    "    - Coding queries: Respond ONLY with: USE_CODE: <valid Python code>\n",
    "        Do NOT execute the code yourself or provide explanations unless explicitly asked. Provide runnable, well-formatted Python code snippets that directly solve the problem.\n",
    "    - File operations and text editing queries: Respond ONLY with: USE_FILE: <valid Python code>\n",
    "        Generate a Python script that performs the requested file manipulation or text modification (e.g., copying files, reading, writing, replacing text, formatting). \n",
    "        The script should be self-contained, executable, and clearly named variables. Do NOT execute the code yourself or provide explanations unless explicitly asked.\n",
    "    - General knowledge: Give concise, factual answers without unnecessary detail or speculation.\n",
    "    - Translation requests: Translate exactly as requested without explanations or commentary.\n",
    "    - Multi-step reasoning: Break down reasoning steps clearly and concisely in logical order.\n",
    "    Always keep your responses clear and strictly aligned to the query type. Do NOT mix response styles.\n",
    "    For file and text editing, always respond with a Python script showing how to perform the task exactly as asked.\n",
    "    \"\"\"\n",
    "\n",
    "    config = types.GenerateContentConfig(\n",
    "        system_instruction=system_message,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    user_message = user_input.strip()\n",
    "\n",
    "    response = gemini_client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash\",\n",
    "        config=config,\n",
    "        contents=user_message,\n",
    "    )\n",
    "\n",
    "    print(response)\n",
    "\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca22d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_expression(expression: str) -> str:\n",
    "    print(f\"Evaluating expression: {expression}\")\n",
    "    print(\"-\" * 20)\n",
    "    result = aeval(expression)\n",
    "\n",
    "    if aeval.error:\n",
    "        print(f\"Error evaluating expression: {aeval.error}\")\n",
    "        print(\"-\" * 20)\n",
    "        return f\"Error: {aeval.error}\"\n",
    "    \n",
    "    return result\n",
    "\n",
    "def parse_response(response):\n",
    "    print(f\"Raw response: {response}\")\n",
    "    print(\"-\" * 20)\n",
    "    match = re.match(r\"USE_CALCULATOR:\\s*(.+)\", response)\n",
    "    if match:\n",
    "        expression = match.group(1)\n",
    "        return f\"Result: {eval_expression(expression)}\"\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17eef989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates=[Candidate(content=Content(parts=[Part(video_metadata=None, thought=None, inline_data=None, code_execution_result=None, executable_code=None, file_data=None, function_call=None, function_response=None, text=\"USE_FILE: ```python\\nimport os\\n\\nfilename = 'example.txt'\\ntemp_filename = filename + '.tmp'\\n\\nwith open(filename, 'r') as infile, open(temp_filename, 'w') as outfile:\\n    for line in infile:\\n        outfile.write(line.replace('foo', 'bar'))\\n\\nos.replace(temp_filename, filename)\\n```\")], role='model'), citation_metadata=None, finish_message=None, token_count=None, finish_reason=<FinishReason.STOP: 'STOP'>, avg_logprobs=-0.03794512083364088, grounding_metadata=None, index=None, logprobs_result=None, safety_ratings=None)] create_time=None response_id=None model_version='gemini-2.0-flash' prompt_feedback=None usage_metadata=GenerateContentResponseUsageMetadata(cache_tokens_details=None, cached_content_token_count=None, candidates_token_count=86, candidates_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=86)], prompt_token_count=300, prompt_tokens_details=[ModalityTokenCount(modality=<MediaModality.TEXT: 'TEXT'>, token_count=300)], thoughts_token_count=None, tool_use_prompt_token_count=None, tool_use_prompt_tokens_details=None, total_token_count=386, traffic_type=None) automatic_function_calling_history=[] parsed=None\n",
      "Raw response: USE_FILE: ```python\n",
      "import os\n",
      "\n",
      "filename = 'example.txt'\n",
      "temp_filename = filename + '.tmp'\n",
      "\n",
      "with open(filename, 'r') as infile, open(temp_filename, 'w') as outfile:\n",
      "    for line in infile:\n",
      "        outfile.write(line.replace('foo', 'bar'))\n",
      "\n",
      "os.replace(temp_filename, filename)\n",
      "```\n",
      "--------------------\n",
      "USE_FILE: ```python\n",
      "import os\n",
      "\n",
      "filename = 'example.txt'\n",
      "temp_filename = filename + '.tmp'\n",
      "\n",
      "with open(filename, 'r') as infile, open(temp_filename, 'w') as outfile:\n",
      "    for line in infile:\n",
      "        outfile.write(line.replace('foo', 'bar'))\n",
      "\n",
      "os.replace(temp_filename, filename)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "result = send_message(\"Change all the occurrences of 'foo' to 'bar' in the file 'example.txt'.\")\n",
    "\n",
    "print(parse_response(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
